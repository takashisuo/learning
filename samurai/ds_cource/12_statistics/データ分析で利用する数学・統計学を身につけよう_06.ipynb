{"cells":[{"cell_type":"markdown","metadata":{"id":"tNS2zuP7Afpm"},"source":["# 6章 統計学を学ぼう（分類）"]},{"cell_type":"markdown","metadata":{"id":"RVopHrlgCIAs"},"source":["* 木工場において：分岐前の状態から、不純度が大きく下がる分岐をよい条件分岐とします。\n","* 例えば、不純度=0の場合、ノードはまったく同じクラスのデータだけで構成されている完全に純粋な状態です。\n","* 一方、不純度が高い場合は、さまざまなクラスのデータが混在していることを示しています。\n","\n","    - 不純度が低いということは、ノードがより純粋であり、同じクラスのデータが多く含まれていることを意味します。\n","例えば、不純度=0の場合、ノードはまったく同じクラスのデータだけで構成されている完全に純粋な状態です。\n","一方、不純度が高い場合は、さまざまなクラスのデータが混在していることを示しています。\n","決定木アルゴリズムでは、不純度が最も減少する特徴量で分割を行うことで、ノードの純粋度を高めていきます。純粋度が高まれば、より良い分類が可能になります。\n","したがって、決定木構築においては、ノードの不純度を低く保つことが目標となります。各ノードで不純度を計算し、不純度減少が最大になる特徴量で分割を行うことで、段階的に不純度を下げていきます。"]},{"cell_type":"markdown","metadata":{"id":"VfhhI75RHl29"},"source":["# 実践2-1\n","\n","y=x^2のある値での傾き(微分)を求める計算式を定義してください。\n","変化点を小さくすることで算出してください。\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-1l4w2FL80wz"},"outputs":[],"source":["def derivative(x):\n","    \"\"\"\n","    y = x^2 の x における微分値を計算する関数\n","\n","    Args:\n","        x (float): 微分点の値\n","\n","    Returns:\n","        float: x における微分値\n","    \"\"\"\n","    h = 0.00001  # 刻み幅\n","\n","    # 数値微分による近似\n","    return (pow(x + h, 2) - pow(x, 2)) / h"]},{"cell_type":"markdown","metadata":{"id":"N0z9qcxAH6_J"},"source":["# 実践2-2(応用)\n","任意の関数を受け取ってその関数の傾き(微分)を求める計算式を関数で定義してください。\n","(関数の引数に関数を渡す: 総合演習17-9参照)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RZ4ARv3jH5uH"},"outputs":[],"source":["def derivative(func, x, h=0.00001):\n","    \"\"\"\n","    数値微分を用いて、関数funcのxにおける導関数を近似計算する\n","\n","    Parameters:\n","    func (callable): 微分する関数\n","    x (float): 微分点\n","    h (float): 刻み幅 (デフォルト値は0.00001)\n","\n","    Returns:\n","    float: 近似された導関数値\n","    \"\"\"\n","    # 前進差分による近似\n","    return (func(x + h) - func(x)) / h\n","\n","# 例: x^2の導関数をx=3で計算\n","def square(x):\n","    return x ** 2\n","\n","result = derivative(square, 3)\n","print(f\"x^2 at x=3, derivative = {result}\")  # 出力: x^2 at x=3, derivative = 6.000009999831776"]},{"cell_type":"markdown","metadata":{"id":"P5i0nnPnAMZ4"},"source":["# 実践3-1:行列演算\n","以下の演算を実施してください。\n","\n","1. ベクトル同士の足し算・引き算\n","\n","    (a) 足し算:\n","    u = (2, -3, 5),\n","    \n","    v = (-1, 4, 1)\n","    \n","    u + vを計算せよ。\n","\n","    (b) 引き算:\n","\n","    x = (7, -2, 4),\n","    \n","    y = (3, 5, -1)  \n","    \n","    x - yを計算せよ。\n","\n","2. 行列同士の足し算・引き算  \n","\n","    (a) 足し算:\n","    A = \\begin{pmatrix}\n","    1 & 2 & 0\\\\\n","    3 & -1 & 4\\\\\n","    \\end{pmatrix}, B = \\begin{pmatrix}\n","    4 & 1 & 2\\\\\n","    -2 & 3 & 1\\\\  \n","    \\end{pmatrix}\n","    A + Bを計算せよ。\n","\n","    (b) 引き算:  \n","    C = \\begin{pmatrix}\n","    5 & 7 & 2\\\\\n","    -3 & 4 & 6\\\\\n","    1 & -2 & 3\\\\\n","    \\end{pmatrix}, D = \\begin{pmatrix}\n","    2 & -1 & 4\\\\\n","    6 & 3 & -2\\\\\n","    -4 & 1 & 5\\\\\n","    \\end{pmatrix}\n","    C - Dを計算せよ。\n","\n","3. ベクトルのスカラー倍\n","\n","    u = (2, -5, 3)\n","    \n","    2uを計算せよ。\n","\n","4. 行列のスカラー倍  \n","\n","    A = \\begin{pmatrix}\n","    1 & 4 & 2\\\\\n","    3 & -2 & 5\\\\\n","    \\end{pmatrix}\n","    -3Aを計算せよ。  \n","\n","5. 行列同士の掛け算 (3×2)  \n","\n","    A = \\begin{pmatrix}\n","    2 & 1\\\\\n","    3 & 4\\\\\n","    5 & 2\\\\\n","    \\end{pmatrix}, B = \\begin{pmatrix}\n","    6 & 3\\\\\n","    2 & 7\\\\\n","    \\end{pmatrix}\n","    ABを計算せよ。\n","\n","6. 行列とベクトルの掛け算\n","\n","    A = \\begin{pmatrix}\n","    1 & 2 & 3\\\\\n","    4 & 5 & 6\\\\  \n","    \\end{pmatrix}, u = \\begin{pmatrix}\n","    2\\\\\n","    3\\\\\n","    1\\\\\n","    \\end{pmatrix}\n","    Auを計算せよ。\n","\n","7. 行列と単位行列の掛け算\n","\n","    A = \\begin{pmatrix}\n","    2 & 3 & 1\\\\\n","    4 & 0 & 2\\\\\n","    5 & 6 & 7\\\\\n","    \\end{pmatrix}  \n","    AI3を計算せよ。(I3は3×3の単位行列)\n","\n","8. 2×2の逆行列\n","\n","    A = \\begin{pmatrix}\n","    3 & 2\\\\\n","    1 & 4\\\\  \n","    \\end{pmatrix}\n","    A^{-1}を計算せよ。\n"]},{"cell_type":"markdown","metadata":{"id":"a41RztJcCYtb"},"source":["**解答**\n","\n","1. ベクトル同士の足し算・引き算\n","\n","    (a) 足し算: u = (2, -3, 5), v = (-1, 4, 1)\n","    \n","    u + v = (2 + (-1), -3 + 4, 5 + 1) = (1, 1, 6)\n","\n","    (b) 引き算: x = (7, -2, 4), y = (3, 5, -1)\n","    \n","    x - y = (7 - 3, -2 - 5, 4 - (-1)) = (4, -7, 5)\n","\n","2. 行列同士の足し算・引き算\n","\n","    (a) 足し算:\n","    \n","    A = \\begin{pmatrix}\n","    1 & 2 & 0\\\\\n","    3 & -1 & 4\\\\\n","    \\end{pmatrix},\n","    B = \\begin{pmatrix}\n","    4 & 1 & 2\\\\\n","    -2 & 3 & 1\\\\\n","    \\end{pmatrix}\n","    A + B = \\begin{pmatrix}\n","    5 & 3 & 2\\\\\n","    1 & 2 & 5\\\\\n","    \\end{pmatrix}\n","\n","    (b) 引き算:\n","    \n","    C = \\begin{pmatrix}\n","    5 & 7 & 2\\\\\n","    -3 & 4 & 6\\\\\n","    1 & -2 & 3\\\\\n","    \\end{pmatrix}, D = \\begin{pmatrix}\n","    2 & -1 & 4\\\\\n","    6 & 3 & -2\\\\\n","    -4 & 1 & 5\\\\\n","    \\end{pmatrix}\n","    C - D = \\begin{pmatrix}\n","    3 & 8 & -2\\\\\n","    -9 & 1 & 8\\\\\n","    5 & -3 & -2\\\\\n","    \\end{pmatrix}\n","\n","3. ベクトルのスカラー倍\n","\n","    ベクトルのスカラー倍: u = (2, -5, 3)\n","\n","    2u = 2(2, -5, 3) = (4, -10, 6)\n","\n","4. 行列のスカラー倍  \n","\n","    行列のスカラー倍: A = \\begin{pmatrix}\n","    1 & 4 & 2\\\\\n","    3 & -2 & 5\\\\\n","    \\end{pmatrix}\n","    -3A = \\begin{pmatrix}\n","    -3 & -12 & -6\\\\\n","    -9 & 6 & -15\\\\\n","    \\end{pmatrix}\n","\n","5. 行列同士の掛け算 (3×2)  \n","\n","    行列の積 (3×2): A = \\begin{pmatrix}\n","    2 & 1\\\\\n","    3 & 4\\\\\n","    5 & 2\\\\\n","    \\end{pmatrix}, B = \\begin{pmatrix}\n","    6 & 3\\\\\n","    2 & 7\\\\\n","    \\end{pmatrix}\n","    AB = \\begin{pmatrix}\n","    14 & 13\\\\\n","    26 & 37\\\\\n","    34 & 29\\\\\n","    \\end{pmatrix}\n","\n","6. 行列とベクトルの掛け算\n","\n","    行列とベクトルの積:\n","    \n","    A = \\begin{pmatrix}\n","    1 & 2 & 3\\\\\n","    4 & 5 & 6\\\\\n","    \\end{pmatrix}, u = \\begin{pmatrix}\n","    2\\\\\n","    3\\\\\n","    1\\\\\n","    \\end{pmatrix}\n","    Au = \\begin{pmatrix}\n","    12 + 23 + 31\\\\\n","    42 + 53 + 61\\\\\n","    \\end{pmatrix}\n","    = \\begin{pmatrix}\n","    11\\\\\n","    29\\\\\n","    \\end{pmatrix}\n","\n","7. 行列と単位行列の掛け算\n","\n","    行列と単位行列の積:\n","    \n","    A = \\begin{pmatrix}\n","    2 & 3 & 1\\\\\n","    4 & 0 & 2\\\\\n","    5 & 6 & 7\\\\\n","    \\end{pmatrix}, I3は3×3の単位行列\n","\n","    AI3 = \\begin{pmatrix}\n","    2 & 3 & 1\\\\\n","    4 & 0 & 2\\\\\n","    5 & 6 & 7\\\\\n","    \\end{pmatrix}\n"]},{"cell_type":"markdown","metadata":{"id":"j0m-CKw-Hq4H"},"source":["# 実践4-1(統計)\n","サンプルデータ\n","生徒10人の数学とプログラミングの試験点数が以下のように与えられています。\n","数学: [75, 82, 91, 64, 88, 73, 95, 67, 81, 70]\n","プログラミング: [85, 76, 92, 68, 79, 81, 88, 65, 73, 87]\n","\n","問題1: 平均値を求める\n","数学とプログラミングの試験点数それぞれの平均点を求めてください。\n","\n","問題2: 中央値を求める\n","数学とプログラミングの試験点数それぞれの中央値を求めてください。\n","\n","問題3: 最頻値を求める\n","数学とプログラミングの試験点数それぞれの最頻値を求めてください。\n","\n","問題4: 標準偏差と分散を求める\n","数学とプログラミングの試験点数それぞれの標準偏差と分散を求めてください。\n","\n","問題5: 相関係数を求める\n","数学とプログラミングの試験点数の相関係数を求めてください。\n","これらの問題を解くために、平均値、中央値、最頻値、標準偏差、分散、相関係数を計算する関数を作成し、サンプルデータを使って解答の一部を埋めてください。リストの標準ライブラリのみを使用してください。\n","\n","\n","```\n","from math import sqrt\n","\n","# サンプルデータ\n","math_scores = [75, 82, 91, 64, 88, 73, 95, 67, 81, 70]\n","prog_scores = [85, 76, 92, 68, 79, 81, 88, 65, 73, 87]\n","\n","# 問題1: 平均値\n","def mean(scores):\n","    # ここを埋める\n","\n","math_mean = mean(math_scores)\n","prog_mean = mean(prog_scores)\n","print(f\"数学の平均点: {math_mean}\")\n","print(f\"プログラミングの平均点: {prog_mean}\")\n","\n","# 問題2: 中央値\n","def median(scores):\n","    sorted_scores = sorted(scores)\n","    n = len(sorted_scores)\n","    # 残りの処理を埋める\n","\n","math_median = median(math_scores)\n","prog_median = median(prog_scores)\n","print(f\"数学の中央値: {math_median}\")\n","print(f\"プログラミングの中央値: {prog_median}\")\n","\n","# 問題3: 最頻値\n","def mode(scores):\n","    count = {}\n","    for score in scores:\n","        count[score] = count.get(score, 0) + 1\n","    # 以降を埋める\n","\n","math_mode = mode(math_scores)\n","prog_mode = mode(prog_scores)\n","print(f\"数学の最頻値: {math_mode}\")\n","print(f\"プログラミングの最頻値: {prog_mode}\")\n","\n","# 問題4: 標準偏差と分散\n","def stdev(scores):\n","    mean_val = mean(scores)\n","    # 以降を埋める\n","\n","def variance(scores):\n","    mean_val = mean(scores)\n","    # 以降を埋める\n","\n","\n","math_std = stdev(math_scores)\n","prog_std = stdev(prog_scores)\n","math_var = variance(math_scores)\n","prog_var = variance(prog_scores)\n","print(f\"数学の標準偏差: {math_std}\")\n","print(f\"プログラミングの標準偏差: {prog_std}\")\n","print(f\"数学の分散: {math_var}\")\n","print(f\"プログラミングの分散: {prog_var}\")\n","\n","# 問題5: 相関係数(応用: 数式を確認する必要がある)\n","def covariance(x, y):\n","    x_mean = mean(x)\n","    y_mean = mean(y)\n","    cov = sum((x_i - x_mean) * (y_i - y_mean) for x_i, y_i in zip(x, y))\n","    return cov / (len(x) - 1)\n","\n","def corr_coef(x, y):\n","    # 定義する\n","\n","corr = corr_coef(math_scores, prog_scores)\n","print(f\"数学とプログラミングの相関係数: {corr}\")\n","```\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_YDa-qCLYqz"},"outputs":[],"source":["from math import sqrt\n","\n","# サンプルデータ\n","math_scores = [75, 82, 91, 64, 88, 73, 95, 67, 81, 70]\n","prog_scores = [85, 76, 92, 68, 79, 81, 88, 65, 73, 87]\n","\n","# 問題1: 平均値\n","def mean(scores):\n","    return sum(scores) / len(scores)\n","\n","math_mean = mean(math_scores)\n","prog_mean = mean(prog_scores)\n","print(f\"数学の平均点: {math_mean}\")\n","print(f\"プログラミングの平均点: {prog_mean}\")\n","\n","# 問題2: 中央値\n","def median(scores):\n","    sorted_scores = sorted(scores)\n","    n = len(sorted_scores)\n","    if n % 2 == 0:\n","        middle1 = sorted_scores[n // 2 - 1]\n","        middle2 = sorted_scores[n // 2]\n","        return (middle1 + middle2) / 2\n","    else:\n","        return sorted_scores[n // 2]\n","\n","math_median = median(math_scores)\n","prog_median = median(prog_scores)\n","print(f\"数学の中央値: {math_median}\")\n","print(f\"プログラミングの中央値: {prog_median}\")\n","\n","# 問題3: 最頻値\n","def mode(scores):\n","    count = {}\n","    for score in scores:\n","        count[score] = count.get(score, 0) + 1\n","    max_count = max(count.values())\n","    modes = [k for k, v in count.items() if v == max_count]\n","    return modes\n","\n","math_mode = mode(math_scores)\n","prog_mode = mode(prog_scores)\n","print(f\"数学の最頻値: {math_mode}\")\n","print(f\"プログラミングの最頻値: {prog_mode}\")\n","\n","# 問題4: 標準偏差と分散\n","def stdev(scores):\n","    mean_val = mean(scores)\n","    squared_diffs = [(x - mean_val) ** 2 for x in scores]\n","    variance = sum(squared_diffs) / (len(scores) - 1)\n","    return sqrt(variance)\n","\n","def variance(scores):\n","    mean_val = mean(scores)\n","    squared_diffs = [(x - mean_val) ** 2 for x in scores]\n","    return sum(squared_diffs) / (len(scores) - 1)\n","\n","math_std = stdev(math_scores)\n","prog_std = stdev(prog_scores)\n","math_var = variance(math_scores)\n","prog_var = variance(prog_scores)\n","print(f\"数学の標準偏差: {math_std}\")\n","print(f\"プログラミングの標準偏差: {prog_std}\")\n","print(f\"数学の分散: {math_var}\")\n","print(f\"プログラミングの分散: {prog_var}\")\n","\n","# 問題5: 相関係数\n","def covariance(x, y):\n","    x_mean = mean(x)\n","    y_mean = mean(y)\n","    cov = sum((x_i - x_mean) * (y_i - y_mean) for x_i, y_i in zip(x, y))\n","    return cov / (len(x) - 1)\n","\n","def corr_coef(x, y):\n","    x_std = stdev(x)\n","    y_std = stdev(y)\n","    cov = covariance(x, y)\n","    return cov / (x_std * y_std)\n","\n","corr = corr_coef(math_scores, prog_scores)\n","print(f\"数学とプログラミングの相関係数: {corr}\")"]},{"cell_type":"markdown","metadata":{"id":"HGCVTXclLsKU"},"source":["# 実践4-2\n","標準正規分布について調べて報告してください。正規分布との違いは何ですか？"]},{"cell_type":"markdown","metadata":{"id":"BPOKLYe-L6Sf"},"source":["**解答**\n","\n","**標準正規分布(Standard Normal Distribution)** とは、正規分布の一種で、以下の性質を持つ確率分布です。\n","\n","- 平均(μ)が0\n","- 標準偏差(σ)が1\n","- 確率密度関数: f(x) = (1/sqrt(2π)) * exp(-(x^2/2))\n","\n","標準正規分布の確率密度関数のグラフは、平均0、標準偏差1の釣鐘型の曲線になります。\n","\n","一方、一般的な **正規分布(Normal Distribution)** は、任意の平均μと標準偏差σを持つ確率分布です。確率密度関数は以下のようになります。\n","\n","- 確率密度関数: f(x) = (1/sqrt(2πσ^2)) * exp(-(x-μ)^2/(2σ^2))\n","\n","正規分布と標準正規分布の**違い**は以下の点にあります。\n","\n","1. **平均と標準偏差の値**\n","    - 標準正規分布の平均は0、標準偏差は1と固定\n","    - 正規分布の平均μと標準偏差σは任意の値\n","\n","2. **確率密度関数の式**\n","    - 標準正規分布はxがそのまま使われる\n","    - 正規分布は(x-μ)/σで標準化された値が使われる\n","\n","3. **利用方法の違い**\n","    - 標準正規分布は、確率計算や統計的推定によく使われる\n","    - 正規分布は、実データの近似モデルとしてよく使われる\n","\n","実際には、データを標準化(平均0、分散1に変換)して標準正規分布を使うことが多いです。\n","一般の正規分布は、実データの分布をモデル化する際に使われます。\n","\n","つまり、標準正規分布は理論的な分布であり、正規分布はデータに適合させる経験的な分布であると言えます。\n","両者は密接な関係があり、標準化を介して相互変換できます。"]},{"cell_type":"markdown","metadata":{"id":"vwFF2xZIL8qq"},"source":["# 実践4-3(応用):\n","二項分布・ポアソン分布・指数分布・ベルヌーイ分布・幾何分布について調べて報告してください。"]},{"cell_type":"markdown","metadata":{"id":"S6xa4j1cMXtJ"},"source":["**解答**\n","\n","【二項分布】\n","\n","*   成功/失敗の2値的な結果を持つ試行を繰り返した時の、成功回数の分布\n","* 例えば、コイン投げの表が出る回数がこれにあたる\n","* パラメータは試行回数n、成功確率p\n","\n","【ポアソン分布】\n","\n","* 単位時間/空間内で発生するある事象の発生回数の分布\n","* 例えば、単位時間あたりの電話の着信回数がこれにあたる\n","* パラメータは平均発生回数λのみ\n","\n","【指数分布】\n","\n","* ある事象が発生するまでの時間間隔(待ち時間)の分布\n","* 例えば、ウェブサイトの到着時間間隔がこれにあたる\n","* パラメータは平均発生率λ\n","\n","【ベルヌーイ分布】\n","\n","* 単一の試行で2つの結果(成功/失敗)が発生する分布の基礎\n","* 例えば、コイン投げの表か裏がこれにあたる\n","* パラメータは成功確率pのみ\n","\n","【幾何分布】\n","\n","* 最初の成功が発生するまでの失敗回数の分布\n","* 例えば、ある医療行為を行うまでの失敗回数がこれにあたる\n","* パラメータは成功確率p\n","\n","これらの分布は、様々な確率現象をモデル化するのに役立ちます。\n","正規分布は連続した値を扱いますが、上記の分布は離散的なデータを扱うのに適しています。\n","状況に応じて使い分ける必要があります。"]},{"cell_type":"markdown","metadata":{"id":"DMKdYpc3NEsu"},"source":["# 実践4-4:\n","パラメトリック・ノンパラメトリックという用語について調べて報告してください。\n"]},{"cell_type":"markdown","metadata":{"id":"K9YaFh8XNcCr"},"source":["**解答**\n","\n","パラメトリックとノンパラメトリックは、統計的手法を分類する際の重要な概念です。\n","\n","【パラメトリック手法】\n","- データがある特定の確率分布(正規分布など)に従うと仮定する\n","- その確率分布のパラメータ(平均、分散など)を推定する\n","- 例えば正規分布の平均と分散を推定する場合がこれにあたる\n","- パラメトリック手法は、適切な分布を仮定できれば大変強力\n","- しかし、分布の仮定が外れると結果が歪む危険性がある\n","\n","【ノンパラメトリック手法】\n","- データの確率分布を何も仮定しない\n","- パラメータを推定する必要がない\n","- 代わりに中央値、順位和などの頑健な統計量を使用する\n","- ノンパラメトリック手法は分布の仮定を必要としないので柔軟\n","- しかし分布の情報を使わないため、効率が低下する可能性がある\n","\n","パラメトリック手法とノンパラメトリック手法は以下のようにトレードオフの関係にあります:\n","\n","- パラメトリック手法は強力だが、仮定に敏感\n","- ノンパラメトリック手法は柔軟だが、効率が低い可能性\n","\n","実務では以下のように使い分けられることが多いです:\n","\n","- 理論的裏付けや先行研究があり、分布が明確にわかっている場合は、パラメトリック手法を使用\n","- 分布が不明瞭で探索的な分析が必要な場合は、ノンパラメトリック手法を使用\n","\n","状況に応じて適切な手法を選ぶことが重要です。また、両者を組み合わせる場合もあります。"]},{"cell_type":"markdown","metadata":{"id":"D5oOSNT6_pds"},"source":["# 実践5-1(回帰)\n","最小二乗法について説明してください。"]},{"cell_type":"markdown","metadata":{"id":"TUdZrWWdD4No"},"source":["**解答**\n","\n","最小二乗法(least squares method)は、データから直線や曲線の係数を推定する手法です。\n","具体的には、データ点と推定した直線や曲線との残差(誤差)の2乗和を最小化することで、最適な係数を見つけます。\n","つまり、\n","\n","* 仮説関数(直線や曲線のモデル)を設定\n","* それぞれのデータ点とモデルの残差の2乗和を計算\n","* その2乗和が最小になるようにモデルの係数を調整\n","\n","このようにして、データに最も適合するモデル係数が得られます。\n","単回帰や重回帰分析で広く用いられており、線形モデルにおける基本的な手法です。計算が比較的容易で、ロバスト性があり、解釈性が高いなどの利点があります。"]},{"cell_type":"markdown","metadata":{"id":"R_-SNZDjDmGK"},"source":["# 実践5-2:\n","過学習について説明してください。\n","過学習が起きると何が問題でしょうか。\n"]},{"cell_type":"markdown","metadata":{"id":"DmNx2eahD0Pv"},"source":["**解答**\n","\n","過学習とは、機械学習モデルが訓練データに過度に適合してしまい、未知のデータに対する一般化能力が低下する現象のことです。つまり、モデルが訓練データの特徴やノイズまでも学習してしまうため、新しいデータに対する予測精度が下がってしまいます。\n","過学習が起きると以下のような問題が生じます:\n","\n","* 汎化性能の低下\n","\n","    モデルが訓練データにだけ特化してしまうため、未知のデータに対する予測精度が下がります。つまり、実際の運用環境で十分な性能が発揮できません。\n","\n","* 過剰適合(オーバーフィッティング)\n","\n","    モデルが訓練データの細かいノイズまで学習してしまうため、本来モデルが捉えるべきデータの一般的な特徴を捉えられなくなります。\n","\n","* 解釈性の低下\n","\n","    過学習したモデルの予測根拠が複雑になり、人間がモデルの振る舞いを理解することが難しくなります。\n","\n","* 計算コストの増大\n","\n","    過学習を防ぐために、モデルの複雑さを制御したり、正則化手法を用いる必要があり、計算コストが増えます。"]},{"cell_type":"markdown","metadata":{"id":"hkzGlF1cD6Vn"},"source":["# 実践5-3:\n","決定係数R^2 を使う場面について説明してください。\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xAwhosoGLFX6"},"source":["**解答**\n","\n","決定係数R^2は、回帰分析における回帰モデルの当てはまり具合を示す指標として使われます。\n","具体的には、\n","\n","* 被説明変数(目的変数)のばらつきのうち、説明変数(独立変数)によってどの程度説明できているかを0から1の範囲の値で表します。\n","* R^2値が1に近いほど、回帰モデルのあてはまりがよいことを意味します。\n","* 逆にR^2値が0に近いほど、モデルの当てはまりが悪いことを示します。\n","\n","R^2は主に以下のような場面で参考にされます。\n","\n","* 複数の回帰モデルを比較し、どのモデルが最もデータによく適合しているかを判断する。\n","* 回帰式にある特定の説明変数を追加することで、モデル全体の当てはまりがどれだけ改善されるかを確認する。\n","* 作成した回帰モデルが、実際にデータをどの程度よく説明できるのかを評価する。"]},{"cell_type":"markdown","metadata":{"id":"VzChGIqQKWNi"},"source":["# 実践5-4:\n","以下の決定係数の算出問題を計算してください。\n","\n","データセット\n","\n","x (年収/万円): 300, 400, 500, 600, 700\n","\n","y (支出額/万円): 150, 220, 300, 380, 420\n","\n","以下のサンプルコードを埋めてください。\n","\n","\n","```\n","import math\n","\n","# データ\n","x = [300, 400, 500, 600, 700]\n","y = [150, 220, 300, 380, 420]\n","n = len(x)\n","\n","# 平均値\n","x_mean = sum(x) / n\n","y_mean = sum(y) / n\n","\n","# 直線の係数 a, b (最小二乗法)\n","numer = sum((x_i - x_mean) * (y_i - y_mean) for x_i, y_i in zip(x, y))\n","denom = sum((x_i - x_mean) ** 2 for x_i in x)\n","a = numer / denom\n","b = y_mean - a * x_mean\n","\n","# 予測値\n","y_pred = [a * x_i + b for x_i in x]\n","\n","# 決定係数\n","ss_res = #ここを埋める\n","ss_tot = #ここを埋める\n","r_squared = 1 - (ss_res / ss_tot)\n","\n","print(f\"直線の係数: a = {a}, b = {b}\")\n","print(f\"決定係数 R^2 = {r_squared}\")\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3eCr5JIFLst1"},"source":["**解答**\n","\n","\n","\n","```\n","ss_res = sum((y_i - y_pred_i)**2 for y_i, y_pred_i in zip(y, y_pred))\n","ss_tot = sum((y_i - y_mean)**2 for y_i in y)\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"ST3aigW9FSGt"},"source":["# 実践5-5\n","単回帰と重回帰の違いを数式を例にして説明してください。"]},{"cell_type":"markdown","metadata":{"id":"b3n8303PFgFc"},"source":["**解答**\n","\n","単回帰と重回帰の違いは、説明変数の数が異なることです。\n","\n","【単回帰】\n","単回帰は1つの説明変数xからターゲット変数yを予測するモデルです。\n","式は以下のようになります。\n","\n","y = a * x + b\n","\n","ここで、aとbは係数です。\n","\n","【重回帰】\n","重回帰は複数の説明変数x1, x2, ...からターゲット変数yを予測するモデルです。  \n","式は以下のようになります。\n","\n","y = a1 * x1 + a2 * x2 + ... + an * xn + b  \n","\n","ここで、a1, a2, ..., anとbは係数です。\n","\n","単回帰は1つの説明変数xのみを使って予測値yを求めますが、重回帰では複数の説明変数x1, x2, ...を組み合わせて予測値yを求めます。\n","\n","つまり、単回帰と重回帰の式の違いは、説明変数の項が1つか複数かということになります。\n","重回帰の方が、より複雑なモデルを表現でき、予測精度が向上する可能性があります。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJ8CVdZLElTo"},"outputs":[],"source":["import math\n","\n","# データ\n","x = [300, 400, 500, 600, 700]\n","y = [150, 220, 300, 380, 420]\n","n = len(x)\n","\n","# 平均値\n","x_mean = sum(x) / n\n","y_mean = sum(y) / n\n","\n","# 直線の係数 a, b (最小二乗法)\n","numer = sum((x_i - x_mean) * (y_i - y_mean) for x_i, y_i in zip(x, y))\n","denom = sum((x_i - x_mean) ** 2 for x_i in x)\n","a = numer / denom\n","b = y_mean - a * x_mean\n","\n","# 予測値\n","y_pred = [a * x_i + b for x_i in x]\n","\n","# 決定係数\n","ss_res = sum((y_i - y_pred_i) ** 2 for y_i, y_pred_i in zip(y, y_pred))\n","ss_tot = sum((y_i - y_mean) ** 2 for y_i in y)\n","r_squared = 1 - (ss_res / ss_tot)\n","\n","print(f\"直線の係数: a = {a}, b = {b}\")\n","print(f\"決定係数 R^2 = {r_squared}\")"]},{"cell_type":"markdown","metadata":{"id":"Pm8j4DAoFs5e"},"source":["# 実践5-6\n","リッジ回帰・ラッソ回帰・elastic-netの違いについて調べて報告してください。例えば説明変数の数が多い場合はどの手法を使うべきでしょうか？"]},{"cell_type":"markdown","metadata":{"id":"BQih6SgoGKDD"},"source":["**解答**\n","\n","【リッジ回帰: Ridge】\n","- 回帰係数が大きくなり過ぎるのを防ぐ\n","- 全ての説明変数が予測に使われる\n","- 係数はゼロにならない\n","\n","【ラッソ回帰: Lasso】\n","- 重要でない説明変数の係数を正確にゼロにできる\n","- 説明変数の選択が自動的に行われる\n","- ある変数の係数がまったくゼロになる可能性がある\n","\n","【エラスティックネット:ElasticNet】\n","- リッジ回帰とラッソ回帰の長所を合わせ持つ\n","- 変数選択と係数の小さな値への制限の両方ができる\n","\n","簡単に言うと、\n","* リッジ回帰は係数を小さくする\n","* ラッソ回帰は不要な変数を除去する\n","* エラスティックネットは両方の効果を持つ\n","\n","正則化パラメータを調整することで、過学習を抑え、よりよい予測モデルを得ることができます。\n","\n","**以下、詳細のため必要に応じて確認すること。**\n","\n","実務でリッジ回帰、ラッソ回帰、エラスティックネット回帰のどれを選択するかを検討する際は、以下の点に着目する。\n","\n","**1. 説明変数の数**\n","\n","    * 説明変数が多数ある場合は、ラッソ回帰やエラスティックネットが有効\n","        - 不要な変数を自動的に除去でき、モデルを簡素化できる\n","    * 説明変数が少数の場合は、リッジ回帰でも問題ない\n","\n","**2. 多重共線性の有無**\n","    \n","    * 説明変数間に多重共線性がある場合は、リッジ回帰かエラスティックネットがよい\n","    - ラッソは多重共線性がある変数群から1つしか選ばない欠点がある\n","    * 多重共線性がない場合は、ラッソ回帰も有効\n","\n","**3. 変数選択と予測性能のトレードオフ**\n","\n","    * 変数選択が最重要であれば、ラッソ回帰が適している\n","        - 予測性能が最重要であれば、リッジ回帰が適している  \n","    * 両者をある程度満たしたい場合は、エラスティックネットが適切\n","\n","**4. 事前知識**\n","\n","    * 変数の重要性に関する事前知識があれば、その情報を活用できるか検討する\n","        - 重要な変数は残し、不要な変数を除去したい場合はラッソが適する\n","\n","**5. 実装の容易さ**  \n","\n","    * シンプルな実装を求める場合は、リッジ回帰やラッソ回帰の方が容易\n","\n","最終的には、上記の点を考慮し、実データでモデルの学習とチューニングを行い、性能評価指標が最も良いモデルを選択するのが賢明です。\n","状況に応じて柔軟に手法を使い分けることが重要です\n","\n","補足:\n","多重共線性とは、説明変数同士が強い相関関係にあり、独立性が低い状態を指します。この状況下で通常の最小二乗法を用いると、以下の2つの問題が生じます。\n","\n","    * 係数の値が不安定になる\n","    * 分散が大きくなり、係数の信頼性が低下する\n","\n","これらの問題は、共線性の強い変数が係数を過剰に引っ張り合うことで発生します。\n","\n","ラッソ回帰は、係数の値が0になる変数を選択的に作り出すため、多重共線性がある変数群から1つの変数しか選ばない可能性があります。このため、多重共線性があるデータセットには適していません。\n","\n","一方、リッジ回帰とエラスティックネット回帰は以下の理由から、多重共線性への頑健性があります。\n","\n","【リッジ回帰】\n","\n","係数の値を小さくする正則化を行うため、係数が極端な値をとらず安定する\n","共線性の高い変数同士の係数を引き揃えるような作用がある\n","\n","【エラスティックネット回帰】\n","\n","ラッソの変数選択と、リッジの係数を小さくする正則化の両方の効果がある\n","共線性の高い変数同士をグループ化して、係数を適切に制御できる\n","\n","したがって、説明変数間の多重共線性がある場合は、リッジ回帰かエラスティックネット回帰を用いることで、多重共線性による問題を回避し、より頑健で安定したモデル構築が可能になります。"]},{"cell_type":"markdown","metadata":{"id":"KHGY0Sfsu8Q-"},"source":["# 実践6-1(分類: 混同行列/評価指標の定義)\n","以下の実際のラベル値と予測値が与えられています。混同行列、Recall、Precision、F値をそれぞれ計算してください。ライブラリは使わず手計算で行ってその結果を記載してください。\n","\n","補足) Recall=再現率, Precision=適合率\n","\n","実際のラベル値: [1, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n","\n","予測値: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0]"]},{"cell_type":"markdown","metadata":{"id":"DUF2Dfecvomb"},"source":["**解答**\n","\n","* まず、混同行列を計算します。\n","\n","<table>\n","  <tr>\n","    <th> </th>\n","    <th>予測ラベル: 0</th>\n","    <th>予測ラベル: 1</th>\n","  </tr>\n","  <tr>\n","    <td>実際のラベル: 0</td>\n","    <td>3</td>\n","    <td>1</td>\n","  </tr>\n","  <tr>\n","    <td>実際のラベル: 1</td>\n","    <td>2</td>\n","    <td>4</td>\n","  </tr>\n","</table>\n","\n","    TruePositive (TP) = 4\n","    FalsePositive (FP) = 1\n","    FalseNegative (FN) = 2\n","    TrueNegative (TN) = 3\n","\n","* 次に、Recall、Precision、F値を計算します。\n","\n","    Recall = TP / (TP + FN)\n","    = 4 / (4 + 2)\n","    = 0.667\n","\n","    Precision = TP / (TP + FP)\n","    = 4 / (4 + 1)\n","    = 0.8\n","\n","    F値 = 2 * (Precision * Recall) / (Precision + Recall)\n","    = 2 * (0.8 * 0.667) / (0.8 + 0.667)\n","    = 0.727\n","\n","    Recall = 0.667\n","    Precision = 0.8\n","    F値 = 0.727\n","    となります。"]},{"cell_type":"markdown","metadata":{"id":"HLowUXmHArUI"},"source":["# 実践6-2 (応用)\n","* 不純度はGini不純度とエントロピーが代表的です。\n","* エントロピーについて概要を調べてみてください。"]},{"cell_type":"markdown","metadata":{"id":"ZZNxPAWVBRHa"},"source":["**解答**\n","\n","* エントロピーは、決定木のノードの不純度を表す指標の1つです。\n","* データセットの不純度が高ければ、さまざまなクラスが混在していることを意味します。\n","* エントロピーは次の式で定義されます。\n","* エントロピー = -Σ(p(i) * log2(p(i)))\n","ここで、p(i)はクラスiのデータ割合です。\n","エントロピーの値は0から1の範囲で変化します。\n","* エントロピー=0の時、ノードはまったく同じクラスのデータだけで構成されている(完全に純粋)\n","* エントロピー=1の時、すべてのクラスが等しい割合で含まれている(最大の不純度)\n","* 決定木では、各ノードでエントロピーを計算し、エントロピーの減少が最大になる特徴量で分割を行うことで、不純度を減らしていきます。\n","* エントロピーの値は0から1の範囲となり、0に近いほど不純度が低く、1に近いほど不純度が高いことを表します。\n","* エントロピーはGini不純度と並んで、決定木アルゴリズムで広く使われる不純度指標です"]},{"cell_type":"markdown","metadata":{"id":"iBYOHKsgCW98"},"source":["# 実践6-3\n","* 木構造で過学習を防ぐ方法としてどんな方法がありますか？"]},{"cell_type":"markdown","metadata":{"id":"XkBtfKRBCXBC"},"source":["**解答例**\n","\n","* 木構造の深さに上限を設ける\n","* 木構造の葉（条件分岐の最も先の部分）の枚数に上限を設ける\n","* 葉のデータ数に最小値を設ける"]},{"cell_type":"markdown","metadata":{"id":"HJxyIUCkDlwo"},"source":["# 実践6-4(応用)\n","* https://terakoya.sejuku.net/programs/104/chapters/1319#6.4-%E5%88%86%E9%A1%9E%E3%81%AE%E6%B5%81%E3%82%8C\n","* 上記説明でのGini不純度の計算をPythonを用いて計算してみてください。\n","* 計算方法を関数として定義してください。"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716816260268,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"yEx05X6MONDP"},"outputs":[],"source":["#　関数として以下を定義する。\n","def gini_impurity(pass_count: int, fail_count: int) -> float:\n","    \"\"\"\n","    Calculate the Gini impurity for a binary classification problem.\n","\n","    Args:\n","        pass_count (int): The number of passing instances.\n","        fail_count (int): The number of failing instances.\n","\n","    Returns:\n","        float: The Gini impurity value.\n","    \"\"\"\n","    total_count = pass_count + fail_count\n","    if total_count == 0:\n","        return 0\n","    p_pass = pass_count / total_count\n","    p_fail = fail_count / total_count\n","    return 1 - (p_pass ** 2 + p_fail ** 2)"]},{"cell_type":"markdown","metadata":{"id":"oKdvlNkuP58E"},"source":["# 実践7-1(クラスタリング): 応用\n","* 調査問題1: クラスタリングアルゴリズムの種類と特徴\n","    * クラスタリングにはどのようなアルゴリズムがあるか調べてみましょう。代表的なアルゴリズムを3つ調査し、種類、概要、利点・欠点をまとめてください。\n","\n","* 調査問題2: 距離尺度の種類と使い分け\n","    * クラスタリングでは、データ点間の類似性を測る尺度が必要です。様々な距離尺度があるので、代表的な距離尺度とその特徴、使い分けをまとめてください。\n","\n","* 調査問題3: 質的データのクラスタリング\n","    * これまでは数値データを扱いましたが、質的データ(カテゴリデータ)をクラスタリングする方法も考えられます。質的データをクラスタリングする際の工夫点や注意点を調べてみましょう。\n","\n","* 調査問題4: クラスタリング評価指標\n","    * クラスタリング結果の良し悪しを評価する指標があります。代表的な評価指標とその概要、利用シーンをまとめてください。\n","\n","* 調査問題5: クラスタリングの実践的な利用例\n","    * クラスタリングはどのような分野で利用されているか、実践的な利用例を調べてみましょう。マーケティング、画像処理、自然言語処理などの具体例を挙げてください。"]},{"cell_type":"markdown","metadata":{"id":"zKe6wP-lRQ_q"},"source":["調査問題1: クラスタリングアルゴリズムの種類と特徴\n","\n","K-means clustering\n","\n","概要: データをK個のクラスタに分割する代表的な手法\n","利点: 計算が高速、大規模データにも適用可能\n","欠点: 初期値に依存する、クラスタ数を事前に指定する必要がある\n","\n","\n","Hierarchical clustering\n","\n","概要: データをひとつずつクラスタにまとめていく手法\n","利点: クラスタ数を事前に指定する必要がない\n","欠点: 計算コストが高い\n","\n","\n","DBSCAN\n","\n","概要: 密度が高い領域をクラスタとして検出する手法\n","利点: ノイズデータを除去できる、クラスタ数を指定する必要がない\n","欠点: パラメータ設定が難しい\n","\n","\n","\n","調査問題2: 距離尺度の種類と使い分け\n","\n","ユークリッド距離: 一般的な距離尺度\n","マハラノビス距離: 特徴量間の相関を考慮した距離尺度\n","コサイン類似度: ベクトル間の類似度を測る指標で、テキストマイニングなどで使用\n","ジャッカード係数: 集合間の類似度を測る指標で、カテゴリデータに適している\n","\n","調査問題3: 質的データのクラスタリング\n","\n","質的データは数値に変換する(ダミー変数やラベルエンコーディング)\n","距離尺度にはジャッカード係数などの集合類似度が適している\n","混合データ(質的と量的の両方)の場合は、変数のスケーリングが重要\n","\n","調査問題4: クラスタリング評価指標\n","エルボー法: クラスタ数を決める際に、手法内分散のグラフから適切なクラスタ数を判断する\n","Silhouette係数: 各データ点のクラスタへの所属度を測る\n","Calinski-Harabasz指数: クラスタ間の分離度とクラスタ内の凝集度のトレードオフを測る\n","\n","\n","```\n","from sklearn.metrics import calinski_harabasz_score\n","\n","# サンプルデータの生成\n","np.random.seed(42)\n","X, _ = make_blobs(n_samples=100, centers=3, cluster_std=0.60, random_state=0)\n","\n","# k-meansクラスタリングの実行\n","kmeans = KMeans(n_clusters=3, random_state=42)\n","labels = kmeans.fit_predict(X)\n","\n","# Calinski-Harabasz指数の計算\n","ch_score = calinski_harabasz_score(X, labels)\n","```\n","\n","\n","\n","\n","\n","調査問題5: クラスタリングの実践的な利用例\n","\n","マーケティング: 顧客セグメンテーション、製品の推薦\n","画像処理: 類似画像のグループ化、画像検索\n","自然言語処理: 文書クラスタリング、トピックモデリング\n","バイオインフォマティクス: 遺伝子発現データのクラスタリング\n","異常検知: ノイズデータの検出"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u1oBTSlxP7y5"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN2YdSaMNyKWtwgYXoJlrVL","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
