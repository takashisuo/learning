{"cells":[{"cell_type":"markdown","metadata":{"id":"RG6LsHTm0mxR"},"source":["# 12章 分類の手法を学ぼう"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":601,"status":"ok","timestamp":1714399394975,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"M68AH_w40Ggt"},"outputs":[],"source":["import pandas as pd\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1714399395371,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"2g5yhy1N0rJl"},"outputs":[],"source":["from sklearn.datasets import load_breast_cancer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1714399395826,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"va0ygZvj1jTT","outputId":"6b36816f-640f-47d1-9e77-d9b6d91409d5"},"outputs":[],"source":["dataset = load_breast_cancer()\n","display(dataset)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1714399396745,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"wwWcEB9o1msC","outputId":"692a91be-8e90-4dfa-cb88-92edde124023"},"outputs":[],"source":["print(dataset.DESCR)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":290},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1714399397209,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"zm4Xlgjc2aMo","outputId":"9ffb417b-38bd-4266-ea6b-cd681e745bef"},"outputs":[],"source":["df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1714399397726,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"v1y2Dv-A2k_p","outputId":"76982be5-dfbe-4344-97cf-07b73c2b429d"},"outputs":[],"source":["df['class'] = dataset.target\n","display(df.head())\n","display(df.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":737},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1714399397726,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"V_tNJZu33Qja","outputId":"56a6b3ee-50f0-476e-e772-356c417f87c9"},"outputs":[],"source":["display(df.info())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":8043,"status":"ok","timestamp":1714399406158,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"Mu-cN17E3hF_","outputId":"6b3be272-a763-490e-8e01-d962259c9aac"},"outputs":[],"source":["df.hist(figsize=(20, 15), bins=30)\n"]},{"cell_type":"markdown","metadata":{"id":"n-mdInzG5epn"},"source":["## 5. 学習データとテストデータへの分割"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1714399406158,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"sBW2jakV30x6"},"outputs":[],"source":["X = df.drop(columns=['class']).to_numpy()\n","y = df['class'].to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1714399406158,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"aimCQNcN6FbD"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1714399406158,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"SdkiD2CM7NX4","outputId":"a253cce8-eba0-49da-db2f-9cef33e8cbe8"},"outputs":[],"source":["print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"A8KilOv1_rNL"},"source":["## 6. 予測モデルの学習"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1714399406158,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"pd6DPCBm_ueP"},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","model = DecisionTreeClassifier(random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1714399406158,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"wkhADFhx8RfE","outputId":"9c4924e1-3f9e-4081-fdb5-ca5ad6fadea3"},"outputs":[],"source":["model.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"9NV9oTZR8U0J"},"source":["## 7. 予測モデルの評価"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1714399406159,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"n8i7XI-M8YCj","outputId":"0b8f0e49-c45f-41f6-a015-64a1b0e3d51f"},"outputs":[],"source":["y_pred = model.predict(X_test)\n","display(y_pred)\n","display(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1714399406159,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"M0X_fDte9BB8","outputId":"93743f83-da0d-4fbf-f341-de2306092c39"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"8DKiZ_A0IpjQ"},"source":["## 8. 予測"]},{"cell_type":"markdown","metadata":{"id":"P-fWi__LJTQL"},"source":["## 9. 設定したゴールに対する考察"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1714399406159,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"RhMxpg2dIusN","outputId":"3032ec71-a73e-4b57-afba-eb8395201964"},"outputs":[],"source":["from sklearn.tree import export_text\n","# 要素名の取得\n","names = dataset.feature_names\n","# 要素名をリスト形式に変換\n","names_list = names.tolist()\n","# 条件分岐構造を出力\n","print(export_text(model, decimals=3, feature_names=names_list))\n"]},{"cell_type":"markdown","metadata":{"id":"3wzXdV1wK8WP"},"source":["## 12.4 予測モデルの改善"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":394,"status":"ok","timestamp":1714399576709,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"o9_i8ijjLW6L"},"outputs":[],"source":["model = DecisionTreeClassifier(\n","    max_depth=2,\n","    max_leaf_nodes=3,\n","    min_samples_leaf=10,\n","    random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":92},"executionInfo":{"elapsed":557,"status":"ok","timestamp":1714399589179,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"ESNUsspILanD","outputId":"3ae9efe0-f200-4e75-a36c-e0f3c369502d"},"outputs":[],"source":["model.fit(X_train, y_train)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":331},"executionInfo":{"elapsed":426,"status":"ok","timestamp":1714399637633,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"c71mhTVMLe4Z","outputId":"a9fdec1b-16e9-4e62-e2fe-a9d1c71a16cd"},"outputs":[],"source":["y_pred = model.predict(X_test)\n","display(y_pred)\n","print(classification_report(y_test, y_pred))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":397,"status":"ok","timestamp":1714399658379,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"eg56siSlLhok","outputId":"e654ac9e-8ddf-490d-b8be-e836a9c9203c"},"outputs":[],"source":["print(export_text(model, decimals=3, feature_names=names_list))\n"]},{"cell_type":"markdown","metadata":{"id":"-WqrRAPP9XTA"},"source":["# 実践1 (pandasの復習)\n","* 「7. 予測モデルの評価」で実行したclassification_reportをdataframeに格納してください。その後csvとして保存してください。\n","* 実務でもdataframeに格納してcsvへ保存するケースはあります。"]},{"cell_type":"markdown","metadata":{"id":"jk3m4x437lyd"},"source":["# 実践2(matplotlib, seabornの復習 & 一部発展)\n","* load_breast_cancerを講義テキストでは\n","```\n","df.hist(figsize=(20, 15), bins=30)\n","```\n","として実施しました。\n","* これをseabornのstripplotを使って同様に表示してください。その際、全特徴量を1つのfigとして表示し、図を保存してください。\n","* ポイント: subplotsを用いること & for文を使ってstripplotをおこなう。\n","* 参考) 実務でもこのように全特徴量に対して一斉の可視化を行うケース(pandasの可視化だけでは対応できないケース)はあります。一度ロジックを組み立てておけば汎用的に使えるので覚えておくと便利です。\n","* 更に発展させると、この処理のベースを関数/クラスのメソッド化しておき、dataframeを渡すだけにしておくと更に利便性が高まります。\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":11443,"status":"ok","timestamp":1714311688698,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"WuG7AK0i8wY6","outputId":"89d97e7b-4644-4bd1-e674-5abaaf74da1d"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.datasets import load_breast_cancer\n","\n","# Breast Cancerデータセットの読み込み\n","cancer = load_breast_cancer()\n","df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n","\n","# figureとaxesオブジェクトを作成\n","fig, axes = plt.subplots(nrows=8, ncols=4, figsize=(16, 24))\n","axes = axes.ravel() # axesオブジェクトを1次元に平坦化\n","\n","# 各特徴量のstripplotを描画\n","for i, col in enumerate(df.columns):\n","    sns.stripplot(data=df, x=col, ax=axes[i])\n","    axes[i].set_title(col, fontsize=12)\n","    axes[i].tick_params(labelrotation=45)\n","\n","# 余分なaxesを削除\n","for ax in axes[len(df.columns):]:\n","    ax.set_visible(False)\n","\n","# 図のレイアウト調整\n","fig.tight_layout()\n","\n","# 図の保存\n","# fig.savefig('breast_cancer_features_stripplot.png', dpi=300, bbox_inches='tight')"]},{"cell_type":"markdown","metadata":{"id":"pKNcJu1-8r3U"},"source":["# 実践3\n","- 「7. 予測モデルの評価」の流れで混同行列を作成し表示してください。(classification_reportの元となる行列で実務でも利用します)"]},{"cell_type":"markdown","metadata":{"id":"4ehuzE0F2-I6"},"source":["# 実践4(マルチクラス分類)\n","* irisデータを取得してください。\n","```\n","from sklearn.datasets import load_iris\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","```\n","* irisデータに対して学習・推論を実施してください。モデルは任意で構いませんが、木構造以外のアルゴリズムの場合は標準化を視野に入れてください(厳密にはデータによっては標準化が不要な場合もありますが、基本は実施すべきです)。木構造の場合はexport_text等で条件分岐を出力してください。\n","* 混同行列や評価指標を算出してください。\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":11562,"status":"ok","timestamp":1714397415298,"user":{"displayName":"Takashi Suou","userId":"04024765498720654612"},"user_tz":-540},"id":"ISuVytbh8yhA","outputId":"724344f3-cf75-44c1-b06d-942cafc59d67"},"outputs":[],"source":["# 必要なライブラリをインポート\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, classification_report\n","\n","\n","# irisデータセットを読み込む\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# 特徴量と正解ラベルをDataFrameに変換\n","df = pd.DataFrame(X, columns=iris.feature_names)\n","df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n","\n","# 前処理: 特徴量の可視化\n","# pd.plotting.scatter_matrix(df, c=y, figsize=(10, 8), s=100, marker='D')\n","\n","# seabornのpairplotで可視化\n","sns.pairplot(df, hue='species')\n","plt.show()\n","\n","# 学習データとテストデータに分割\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n","\n","# ロジスティック回帰モデルを学習\n","clf = LogisticRegression()\n","clf.fit(X_train, y_train)\n","\n","# テストデータで予測\n","y_pred = clf.predict(X_test)\n","\n","# 評価指標を算出\n","accuracy = accuracy_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred, average='macro')\n","precision = precision_score(y_test, y_pred, average='macro')\n","\n","print(f'Accuracy: {accuracy:.2f}')\n","print(f'Recall: {recall:.2f}')\n","print(f'Precision: {precision:.2f}')\n","\n","# 混同行列を出力\n","cm = confusion_matrix(y_test, y_pred)\n","print('Confusion Matrix:')\n","print(cm)\n","\n","# classification_report\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"AU9eriHp_ntG"},"source":["講義の補足に関する参考)\n","average='macro'は、多クラス分類問題において、各クラスの指標の単純平均を取ることを意味しています。\n","具体的には、以下のように計算されます。\n","\n","- recallの場合\n","\n","    - クラス1のrecallを計算\n","    - クラス2のrecallを計算\n","    - クラス3のrecallを計算\n","    - 上記3つのrecallの平均を取る\n","\n","\n","- precisionの場合も同様に\n","\n","    - クラス1のprecisionを計算\n","    - クラス2のprecisionを計算\n","    - クラス3のprecisionを計算\n","\n","上記3つのprecisionの平均を取る\n","\n","\n","\n","- 一方で、average='micro'とすると、真の正例数と予測された正例数の比から計算されます。classification_reportsのweighted_avgとはまた別です。\n","- クラスが非常に偏っているデータセットの場合、microとmacroで値が大きく異なる可能性があります。\n","- どちらを選ぶかは状況次第ですが、通常は以下のようなケースで使い分けられています。\n","\n","- average='macro' : 各クラスが同等に重要で、偏りのない評価が必要な場合\n","- average='micro' : 総合的な性能評価が重要で、クラスの偏りが問題ない場合\n","\n","今回はマルチクラス分類なので、各クラスが同等に重要と考え、average='macro'を選びました。\n","\n","データの特性によっては、microの方が適切な場合もあるかもしれません。"]},{"cell_type":"markdown","metadata":{"id":"iKKonSuZEFZp"},"source":["\n","それぞれの平均値の計算方法をirisデータセットの実際の値を使って説明します。\n","\n","irisデータセットにはsetosa、versicolor、virginicaの3クラスがあり、classification_reportから得られる値は以下の通りです。\n","```\n","Copy code              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        13\n","  versicolor       0.94      1.00      0.97        16\n","   virginica       1.00      0.91      0.95        11\n","    accuracy                           0.97        40\n","   macro avg       0.98      0.97      0.97        40\n","weighted avg       0.97      0.97      0.97        40\n","\n","```\n","__macro avg__\n","\n","\n","precision = (1.00 + 0.94 + 1.00) / 3 = 0.98\n","\n","recall = (1.00 + 1.00 + 0.91) / 3 = 0.97\n","\n","f1-score = (1.00 + 0.97 + 0.95) / 3 = 0.97\n","\n","macro avgは簡単に各クラスのスコアの平均を取ります。\n","\n","__weighted avg__\n","```\n","precision = (1.00 * 13 + 0.94 * 16 + 1.00 * 11) / 40 = 0.97\n","recall = (1.00 * 13 + 1.00 * 16 + 0.91 * 11) / 40 = 0.97\n","f1-score = (1.00 * 13 + 0.97 * 16 + 0.95 * 11) / 40 = 0.97\n","```\n","\n","weighted avgはサンプル数(support列)を加味して、出現頻度に応じた重み付け平均を計算します。\n","\n","__micro avg__\n","```\n","precision = TP / (TP + FP)\n","= (13 + 16 + 10) / (13 + 16 + 10 + 0 + 0 + 1)\n","= 39 / 40\n","= 0.975\n","recall = TP / (TP + FN)\n","= (13 + 16 + 10) / (13 + 16 + 11)\n","= 39 / 40\n","= 0.975\n","f1-score = 2 * precision * recall / (precision + recall)\n","= 2 * 0.975 * 0.975 / (0.975 + 0.975)\n","= 0.975\n","```\n","micro avgは全体の真陽性(TP)、偽陽性(FP)、偽陰性(FN)から算出されます。クラス間の出現頻度は考慮されません。\n","\n","このように、macro avgはクラス間の偏りを無視、weighted avgはサンプル数の偏りを考慮、micro avgは全体の集計値から算出される、という違いがあります。\n","\n","状況に応じて適切な指標を選ぶ必要があります。\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pt5u-eov-liW"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMQWxp3aN1Z2hyKx1fBZIcK","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
